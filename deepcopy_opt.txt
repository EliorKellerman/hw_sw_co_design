The batching solution for deepcopy worked and resulted in ~48% acceleration for this synthetic benchmark.
Goal: we want to develop a generic wrapper lib for deepcopy that seeks to batch together deepcopy requests,
and it will execute all deepcopies in one batch when it really needs to (similar to copy on write method).
Requirements:
1. When the target data (copied to) is accessed, we must perform the deepcopy.
2. The general way of action for the library is to check on each deepcopy call if we can hold that deepcopy, append the data+target couple to a list,
and later on on data access (which will probably have to be via a handler function now) this will trigger the deepcopy.
3. Need to consider wether there's a way to handle the deepcopy trigger on data access without using a special get_data(a) call from our new library. 
This can also be a hardware solution as an optimization. present both solutions (software with new get_data function, and hardware solution of dedicated hardware
that recognises bwhind the scenes wether accessed data is waiting/stalled on deepcopy). 


py-spy record --rate 250 --subprocesses --output flamegraph.svg --format flamegraph --nonblocking -- python3 pyperformance-main/pyperformance/data-files/benchmarks/bm_deepcopy/single_deepcopy.py